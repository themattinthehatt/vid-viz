{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import os\n",
    "import time\n",
    "import curses\n",
    "import numpy as np\n",
    "import cv2\n",
    "import src.viztools as vv\n",
    "import src.utils as util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    " ### TODO\n",
    " * refactor key input handling across classes (change phase keys in Alien)\n",
    " * border zoom out black masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "007 fps"
     ]
    }
   ],
   "source": [
    "\"\"\"vid-viz main loop\n",
    "\n",
    "KEYBOARD INPUTS:\n",
    "    number keys - choose effect (see viztools.py for detailed keyboard input for each effect)\n",
    "        0 - thresholding\n",
    "        1 - alien\n",
    "        2 - rgbwalk\n",
    "        3 - rgbburst\n",
    "        4 - huebloom\n",
    "        5 - hueswirl\n",
    "        6 - huecrusher\n",
    "    q - quit effect (then number keys are once again available for choosing a new effect)\n",
    "    ` - enable toggling of border effects ('t' to toggle, tab to switch processing/border order)\n",
    "    spacebar - cycle through sources\n",
    "    backspace - quit border effect editing\n",
    "    esc - exit loop\n",
    "\"\"\"\n",
    "\n",
    "# 'cam' | 'video' | 'image' | 'gen'\n",
    "SOURCE_INDEX = 0\n",
    "SOURCE_LIST = []\n",
    "SOURCE_LIST.append({\n",
    "    'file_loc': None,\n",
    "    'file_type': 'cam'})\n",
    "SOURCE_LIST.append({\n",
    "    'file_loc': '/media/data/Dropbox/Git/vid-viz/data/snowflake-02.mp4',\n",
    "    'file_type': 'video'})\n",
    "SOURCE_LIST.append({\n",
    "    'file_loc': '/media/data/Dropbox/Git/vid-viz/data/tree-00.jpg',\n",
    "    'file_type': 'image'})\n",
    "SOURCE_LIST.append({\n",
    "    'file_loc': '/media/data/Dropbox/Git/vid-viz/data/honeycomb-00.jpg',\n",
    "    'file_type': 'image'})\n",
    "# SOURCE_LIST.append({\n",
    "#     'file_loc': '/media/data/Dropbox/Git/vid-viz/data/waves-00.jpg',\n",
    "#     'file_type': 'image'})\n",
    "# SOURCE_LIST.append({\n",
    "#     'file_loc': '/media/data/Dropbox/Git/vid-viz/data/waves-01.jpg',\n",
    "#     'file_type': 'image'})\n",
    "# SOURCE_LIST.append({\n",
    "#     'file_loc': '/media/data/Dropbox/Git/vid-viz/data/waves-02.jpg',\n",
    "#     'file_type': 'image'})\n",
    "# SOURCE_LIST.append({\n",
    "#     'file_loc': '/media/data/Dropbox/Git/vid-viz/data/waves-03.jpg',\n",
    "#     'file_type': 'image'})\n",
    "SOURCE_LIST.append({\n",
    "    'file_loc': '/media/data/Dropbox/Git/vid-viz/data/waves-04.jpg',\n",
    "    'file_type': 'image'})\n",
    "# SOURCE_LIST.append({\n",
    "#     'file_loc': '/media/data/Dropbox/Git/vid-viz/data/waves-05.jpg',\n",
    "#     'file_type': 'image'})\n",
    "\n",
    "SOURCE = None\n",
    "NUM_SOURCES = len(SOURCE_LIST)\n",
    "\n",
    "# general user parameters\n",
    "DISP_FULL_SCREEN = False\n",
    "# FRAME_WIDTH = int(1024)\n",
    "# FRAME_HEIGHT = int(768)\n",
    "FRAME_WIDTH = int(1980/2)\n",
    "FRAME_HEIGHT = int(1200/2)\n",
    "TARGET_FPS = 20.0\n",
    "\n",
    "# initialize key handler\n",
    "effect_index = None\n",
    "key_list = [False for i in range(256)]\n",
    "\n",
    "# set pre/post-processing options\n",
    "post_process = False      # whether or not post-processing is active effect\n",
    "post_process_pre = False  # whether post-processing pre/proceeds other effects\n",
    "\n",
    "# initialize processing objects\n",
    "effects = [\n",
    "    vv.Threshold(),      # 0\n",
    "    vv.Alien(),          # 1\n",
    "    vv.RGBWalk(),        # 2\n",
    "    vv.RGBBurst(),       # 3\n",
    "    vv.HueBloom(),       # 4\n",
    "    vv.HueSwirl(),       # 5\n",
    "    vv.HueSwirlMover(),  # 6\n",
    "    vv.HueCrusher()]     # 7\n",
    "num_effects = len(effects)\n",
    "border = vv.Border()\n",
    "postproc = vv.PostProcess()\n",
    "    \n",
    "new_source = True\n",
    "while(True):\n",
    "\n",
    "    time_pre = time.time()\n",
    "    \n",
    "    # get keyboard input\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    key_list[key] = True\n",
    "    if key == 27:\n",
    "        # escape key; exit program\n",
    "        break\n",
    "    elif key == ord('q'):\n",
    "        # quit current effect\n",
    "        effect_index = None\n",
    "    elif key == ord('\\b'):\n",
    "        post_process = False\n",
    "    elif key == ord('`'):\n",
    "        post_process = True\n",
    "    elif key == ord(' '):\n",
    "        SOURCE_INDEX = (SOURCE_INDEX + 1) % NUM_SOURCES\n",
    "        new_source = True\n",
    "    elif key == ord('\\t'):\n",
    "        # only change post-processing order if in post-process mode\n",
    "        if post_process:\n",
    "            post_process_pre = not post_process_pre\n",
    "            \n",
    "    if new_source:\n",
    "        # reset necessary parameters\n",
    "        new_source = False\n",
    "        effect_index = None\n",
    "        fr_count = 0\n",
    "        for _, effect in enumerate(effects):\n",
    "            effect.reset()\n",
    "        border.reset()\n",
    "        postproc.reset()\n",
    "        # load source\n",
    "        if SOURCE is 'cam' or SOURCE is 'video':\n",
    "            cap.release()\n",
    "        SOURCE = SOURCE_LIST[SOURCE_INDEX]['file_type']\n",
    "        if SOURCE is 'cam':\n",
    "            cap = cv2.VideoCapture(0)\n",
    "            TOTAL_FRAME_COUNT = float('inf')\n",
    "            frame_mask = None\n",
    "        elif SOURCE is 'video':\n",
    "            cap = cv2.VideoCapture(SOURCE_LIST[SOURCE_INDEX]['file_loc'])\n",
    "            # TARGET_FPS = cap.get(cv2.CAP_PROP_FPS)\n",
    "            TOTAL_FRAME_COUNT = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "            frame_mask = None\n",
    "        elif SOURCE is 'image':\n",
    "            frame_orig = cv2.imread(SOURCE_LIST[SOURCE_INDEX]['file_loc'])\n",
    "            TOTAL_FRAME_COUNT = float('inf')\n",
    "            frame_mask = np.copy(frame_orig)   \n",
    "        elif SOURCE is 'gen':\n",
    "            pass\n",
    "        else:\n",
    "            print('Invalid SOURCE type')          \n",
    "    \n",
    "    # get frame and relevant info\n",
    "    if SOURCE is 'cam' or SOURCE is 'video':\n",
    "        ret, frame = cap.read()\n",
    "    elif SOURCE is 'image':\n",
    "        frame = np.copy(frame_orig)\n",
    "    elif SOURCE is 'gen':\n",
    "        frame = None\n",
    "        \n",
    "    # get uniform frame sizes \n",
    "    frame = util.resize(frame, FRAME_WIDTH, FRAME_HEIGHT)\n",
    "    \n",
    "    # update current effect\n",
    "    if effect_index is None:\n",
    "        for num in range(10):\n",
    "            if key == ord(str(num)):\n",
    "                effect_index = num\n",
    "                key_list[key] = False\n",
    "    \n",
    "    # apply borders before effect\n",
    "    if post_process_pre:\n",
    "        if post_process:\n",
    "            frame = border.process(frame, key_list)\n",
    "        else:\n",
    "            frame = border.process(frame, key_list, key_lock=True)\n",
    "    \n",
    "    # process frame\n",
    "    if effect_index is not None and effect_index < num_effects:\n",
    "        if post_process:\n",
    "            frame = effects[effect_index].process(frame, key_list, key_lock=True)            \n",
    "        else:\n",
    "            frame = effects[effect_index].process(frame, key_list)\n",
    "            \n",
    "    # apply borders after effect\n",
    "    if not post_process_pre:\n",
    "        if post_process:\n",
    "            frame = border.process(frame, key_list)\n",
    "#             frame = postproc.process(frame, key_list)\n",
    "        else:\n",
    "            frame = border.process(frame, key_list, key_lock=True)\n",
    "#             frame = postproc.process(frame, key_list, key_lock=True)\n",
    "    \n",
    "    # display frame\n",
    "    if DISP_FULL_SCREEN:\n",
    "        cv2.namedWindow('frame', cv2.WND_PROP_FULLSCREEN)\n",
    "        cv2.setWindowProperty('frame', cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "        cv2.imshow('frame', frame)\n",
    "    else:\n",
    "        cv2.imshow('frame', frame)\n",
    "        if fr_count == 0:\n",
    "            cv2.moveWindow('frame', 0, 0)\n",
    "    \n",
    "    # control animation\n",
    "    fr_count += 1\n",
    "    if fr_count == TOTAL_FRAME_COUNT:\n",
    "        # reset frame postion to 1 (not zero so window isn't moved)\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, 1)\n",
    "        fr_count = 1\n",
    "\n",
    "    # calculate, limit and output fps\n",
    "    time_tot = time.time() - time_pre\n",
    "    if time_tot < 1/TARGET_FPS:\n",
    "        time.sleep(1/TARGET_FPS - time_tot)\n",
    "    time_tot = time.time() - time_pre\n",
    "    print('\\r%03i fps' % (1.0 / time_tot), end='')\n",
    "#     print('\\r%02i' % effects[5].PROPS[4]['VAL'], end='')\n",
    "#     stdscr.addstr(0, 0, '%03i fps' % (1.0 / time_tot))\n",
    "#     stdscr.addstr(1, 0, '%05i frames' % fr_count)\n",
    "#     stdscr.refresh()\n",
    "    \n",
    "#     frame_final = np.copy(frame)\n",
    "    \n",
    "    # reset key list (for pressed keys that are not reset by effect object(s))\n",
    "    key_list[key] = False\n",
    "    \n",
    "if SOURCE is 'cam' or SOURCE is 'video':\n",
    "    cap.release()\n",
    "cv2.destroyWindow('frame')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.utils' from 'src/utils.pyc'>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(vv)\n",
    "reload(util)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "INF = 100000\n",
    "a= 5\n",
    "a = a % INF\n",
    "print(a)\n",
    "print(type(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import PIL.Image\n",
    "PIL.Image.fromarray(frame_final).save('/media/data/Dropbox/image_play/hue-bloom/final/tree-00.jpg', 'jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img1 = cv2.imread('/media/data/Dropbox/Git/vid-viz/data/test_img.png')\n",
    "img1 = util.resize(img1, 1920, 1200)\n",
    "\n",
    "# img0 = 0\n",
    "# img2 = cv2.addWeighted(img0, 0.1, img1, 0.9, 0)\n",
    "# %timeit cv2.addWeighted(img0, 0.1, img1, 0.9, 0)\n",
    "\n",
    "# im_width, im_height, _ = img1.shape\n",
    "# %timeit cv2.warpAffine(img1, \\\n",
    "#             np.float32([[1, 0, 100], \\\n",
    "#                         [0, 1, 200]]), \\\n",
    "#             (im_width, im_height))\n",
    "\n",
    "%timeit cv2.threshold(img1, 128, 255, cv2.THRESH_TOZERO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "frame = cv2.imread('/media/data/Dropbox/Git/vid-viz/data/test_img.png')\n",
    "frame = util.resize(frame, int(1920/2), int(1200/2))\n",
    "\n",
    "# extract hue values\n",
    "frame = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "[im_height, im_width, _] = frame.shape\n",
    "hue_final = np.zeros((im_height, im_width), dtype='uint8')\n",
    "\n",
    "chunk_center = 128\n",
    "chunk_widths_og = 128\n",
    "chunk_width = 8\n",
    "center_offset = 0\n",
    "\n",
    "# human-readable names\n",
    "num_chunks = 3\n",
    "center_offset = 0\n",
    "chunk_width = 8\n",
    "\n",
    "chunk_widths_og = int(256 / num_chunks)\n",
    "chunk_range_mins = np.zeros((num_chunks, 1), 'uint8')\n",
    "chunk_range_maxs = np.zeros((num_chunks, 1), 'uint8')\n",
    "chunk_centers = np.zeros((num_chunks, 1), 'uint8')\n",
    "for chunk in range(num_chunks):\n",
    "    chunk_range_mins[chunk] = chunk * chunk_widths_og\n",
    "    chunk_range_maxs[chunk] = (chunk + 1) * chunk_widths_og - 1\n",
    "    chunk_centers[chunk] = chunk_range_mins[chunk] + int(chunk_widths_og / 2)\n",
    "chunk_range_maxs[-1] = 255\n",
    "    \n",
    "# process image\n",
    "if len(frame.shape) == 3:\n",
    "    [im_height, im_width, _] = frame.shape\n",
    "elif len(frame.shape) == 2:\n",
    "    [im_height, im_width] = frame.shape\n",
    "\n",
    "# extract hue values\n",
    "frame = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "hue_final = np.zeros((im_height, im_width), dtype='uint8')\n",
    "\n",
    "# scale whole image\n",
    "scale = chunk_width / chunk_widths_og\n",
    "frame_scaled = cv2.addWeighted(0, 1 - scale, frame, scale, 0)\n",
    "\n",
    "for chunk in range(num_chunks):\n",
    "\n",
    "    chunk_center = chunk_centers[chunk]\n",
    "\n",
    "    # get rid of values outside bounds of chunk\n",
    "    hue_mask = cv2.inRange(frame[:, :, 0],\n",
    "                           chunk_range_mins[chunk],\n",
    "                           chunk_range_maxs[chunk])\n",
    "    # hue_mask is now a mask for the location of values in a specific\n",
    "    # hue band;\n",
    "    hue = frame_scaled[:, :, 0] + chunk_center - int(chunk_width / 2) + \\\n",
    "        center_offset\n",
    "    hue = cv2.bitwise_and(hue, hue_mask)\n",
    "\n",
    "    # put into final hue array (bitwise or takes all nonzero vals)\n",
    "    hue_final = cv2.bitwise_or(hue_final, hue)\n",
    "\n",
    "# return to bgr format\n",
    "frame[:, :, 0] = hue_final\n",
    "frame = cv2.cvtColor(frame, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "while(True):\n",
    "    \n",
    "    # get keyboard input\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    \n",
    "    print('\\r%g' % key, end='')\n",
    "    \n",
    "    if key == 27:\n",
    "        # escape key\n",
    "        break\n",
    "        \n",
    "    cv2.imshow('frame', frame)\n",
    "        \n",
    "cv2.destroyWindow('frame')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_orig = cv2.imread('/media/data/Dropbox/Git/vid-viz/data/honeycomb_01.jpg')\n",
    "img_orig = cv2.resize(\n",
    "    img_orig,\n",
    "    None,\n",
    "    fx=0.5,\n",
    "    fy=0.5,\n",
    "    interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "# get mask\n",
    "img_gray = cv2.cvtColor(img_orig, cv2.COLOR_BGR2GRAY)\n",
    "img_gray = cv2.medianBlur(img_gray, 11)\n",
    "img_mask = cv2.adaptiveThreshold(\n",
    "    img_gray,\n",
    "    255, # thresh ceil\n",
    "    cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "    cv2.THRESH_BINARY_INV,\n",
    "    21, # thresh block\n",
    "    4 # thresh bias\n",
    ")\n",
    "img_mask2 = cv2.adaptiveThreshold(\n",
    "    img_gray,\n",
    "    255, # thresh ceil\n",
    "    cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "    cv2.THRESH_BINARY,\n",
    "    21, # thresh block\n",
    "    4 # thresh bias\n",
    ")\n",
    "[mask_height, mask_width] = img_mask.shape\n",
    "\n",
    "# get hue background\n",
    "back_height = 10 #int(mask_height/60.0)\n",
    "back_width = 10 #int(mask_width/60.0)\n",
    "img_back = np.ones((back_height, back_width, 3))\n",
    "img_back[:, :, 0] = np.random.rand(back_height, back_width)\n",
    "img_back = cv2.resize(img_back,\n",
    "    (mask_width, mask_height),\n",
    "    interpolation=cv2.INTER_CUBIC)\n",
    "img_back = 255.0 * img_back\n",
    "img_back = img_back.astype('uint8')\n",
    "img_back = cv2.cvtColor(img_back, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "# get blurred background\n",
    "img_back2 = img_back\n",
    "for chan in range(3):\n",
    "    img_back2[:, :, chan] = cv2.bitwise_and(img_back[:, :, chan], img_mask)\n",
    "REDUCE_SIZE = False\n",
    "if REDUCE_SIZE:\n",
    "    img_back2 = cv2.resize(\n",
    "        img_back2,\n",
    "        None,\n",
    "        fx=0.10,\n",
    "        fy=0.10,\n",
    "        interpolation=cv2.INTER_LINEAR)\n",
    "    img_back2 = cv2.GaussianBlur(img_back2, (5,5), 0)\n",
    "    img_back2 = cv2.resize(\n",
    "        img_back2,\n",
    "        (mask_width, mask_height),\n",
    "        interpolation=cv2.INTER_LINEAR)\n",
    "else:\n",
    "    img_back2 = cv2.GaussianBlur(img_back2, (71, 71), 0)\n",
    "\n",
    "# remask blurred background\n",
    "img = img_back2\n",
    "for chan in range(3):\n",
    "    img[:, :, chan] = cv2.bitwise_and(img_back2[:, :, chan], img_mask2)\n",
    "    \n",
    "while(True):\n",
    "    \n",
    "    # get keyboard input\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    \n",
    "    if key == 27:\n",
    "        # escape key\n",
    "        break\n",
    "        \n",
    "    cv2.imshow('frame', img_back2)\n",
    "    cv2.moveWindow('frame', 0, 0)\n",
    "\n",
    "cv2.destroyWindow('frame')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To patrol-cycle an mp4 with ffmpeg\n",
    "* ffmpeg -i source.mp4 -vf reverse source_rev.mp4\n",
    "* ffmpeg -f concat -i concat_list.txt -c copy concated.mp4\n",
    "\n",
    "##### concat_list.txt\n",
    "file '/path/to/vid0.mp4'\n",
    "\n",
    "file '/path/to/vid1.mp4'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
