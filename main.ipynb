{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import os\n",
    "import time\n",
    "import curses\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pyglet\n",
    "\n",
    "import src.viztools as vv\n",
    "import src.utils as util\n",
    "import src.auto as auto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    " ### TODO\n",
    " * refactor key input handling across classes (change phase keys in Alien)\n",
    " * border zoom out black masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------\n",
    "# pyglet\n",
    "# Copyright (c) 2006-2007 Alex Holkner\n",
    "# Copyright (c) 2007 Andrew Straw\n",
    "# All rights reserved.\n",
    "# \n",
    "# Redistribution and use in source and binary forms, with or without\n",
    "# modification, are permitted provided that the following conditions \n",
    "# are met:\n",
    "#\n",
    "#  * Redistributions of source code must retain the above copyright\n",
    "#    notice, this list of conditions and the following disclaimer.\n",
    "#  * Redistributions in binary form must reproduce the above copyright \n",
    "#    notice, this list of conditions and the following disclaimer in\n",
    "#    the documentation and/or other materials provided with the\n",
    "#    distribution.\n",
    "#  * Neither the name of the pyglet nor the names of its\n",
    "#    contributors may be used to endorse or promote products\n",
    "#    derived from this software without specific prior written\n",
    "#    permission.\n",
    "#\n",
    "# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n",
    "# \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n",
    "# LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS\n",
    "# FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE\n",
    "# COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,\n",
    "# INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,\n",
    "# BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\n",
    "# LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n",
    "# CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT\n",
    "# LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN\n",
    "# ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n",
    "# POSSIBILITY OF SUCH DAMAGE.\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "class NumpyImage(pyglet.image.ImageData):\n",
    "    def __init__(self,arr,format=None):\n",
    "        '''Initialize numpy-based image data.\n",
    "\n",
    "        :Parameters:\n",
    "            `arr` : array\n",
    "                numpy array of data. If rank 2, the shape must be\n",
    "                (height, width). If rank 3, the shape is (depth,\n",
    "                height, width). Must be C contiguous.\n",
    "            `format` : str or None\n",
    "                If specified, a format string describing the numpy\n",
    "                array ('L' or 'RGB'). Defaults to a format determined\n",
    "                from the shape of the array.\n",
    "\n",
    "        '''\n",
    "        arr = np.asarray(arr)\n",
    "        if not arr.flags['C_CONTIGUOUS']:\n",
    "            raise ValueError('numpy array must be C contiguous')\n",
    "        if len(arr.shape)==2:\n",
    "            height,width = arr.shape\n",
    "            if format is None:\n",
    "                format = 'L'\n",
    "        elif len(arr.shape)==3:\n",
    "            height,width,depth = arr.shape\n",
    "            if format is None:\n",
    "                if depth==3:\n",
    "                    format = 'RGB'\n",
    "                elif depth==4:\n",
    "                    format = 'RGBA'\n",
    "                elif depth==1:\n",
    "                    format = 'L'\n",
    "                else:\n",
    "                    raise ValueError(\"could not determine a format for depth %d\"%depth)\n",
    "        else:\n",
    "            raise ValueError(\"array must be rank 2 or rank 3\")\n",
    "        data = None\n",
    "        pitch = arr.strides[0]\n",
    "        super(NumpyImage, self).__init__(width, height, format, data, pitch=pitch)\n",
    "        self.arr = arr\n",
    "        self.view_new_array(arr)\n",
    "        \n",
    "    def _convert(self, format, pitch):\n",
    "        if format == self._current_format and pitch == self._current_pitch:\n",
    "            return self.numpy_data_ptr\n",
    "        else:\n",
    "            raise NotImplementedError(\"no support for changing numpy format/pitch\")\n",
    "\n",
    "    def _ensure_string_data(self):\n",
    "        raise RuntimeError(\"we should never get here - we are trying to avoid data copying\")\n",
    "\n",
    "    def dirty(self):\n",
    "        '''Force an update of the texture data.\n",
    "        '''\n",
    "\n",
    "        texture = self.texture\n",
    "        internalformat = None\n",
    "        self.blit_to_texture( texture.target, texture.level, 0, 0, 0, internalformat )\n",
    "        \n",
    "    def view_new_array(self,arr):\n",
    "        '''View a new numpy array of the same shape.\n",
    "\n",
    "        The same texture will be kept, but the data from the new array\n",
    "        will be loaded.\n",
    "\n",
    "        :Parameters:\n",
    "            `arr` : array\n",
    "                numpy array of data. If rank 2, the shape must be\n",
    "                (height, width). If rank 3, the shape is (depth,\n",
    "                height, width).\n",
    "        '''\n",
    "        arr = np.asarray(arr)\n",
    "        if arr.shape != self.arr.shape:\n",
    "            raise ValueError(\"NumpyImage shape changed!\")\n",
    "        if not arr.dtype == np.uint8:\n",
    "            raise ValueError(\"only uint8 numpy arrays supported\")\n",
    "        self.numpy_data_ptr = arr.ctypes.data\n",
    "        self.arr = arr # maintain a reference to numpy array so it's not de-allocated\n",
    "        self.dirty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The enter key was pressed.\n",
      "The left arrow key was pressed.\n",
      "The enter key was pressed.\n",
      "The left arrow key was pressed.\n",
      "The enter key was pressed.\n",
      "The left arrow key was pressed.\n",
      "The enter key was pressed.\n",
      "The left arrow key was pressed.\n",
      "The enter key was pressed.\n",
      "The left arrow key was pressed.\n",
      "The enter key was pressed.\n",
      "The left arrow key was pressed.\n",
      "The enter key was pressed.\n",
      "The left arrow key was pressed.\n"
     ]
    }
   ],
   "source": [
    "from pyglet.window import key\n",
    "\n",
    "disp_full_screen = False\n",
    "frame_width = int(1980/2)\n",
    "frame_height = int(1200/2)\n",
    "\n",
    "# create window with pyglet\n",
    "if disp_full_screen:\n",
    "    window = pyglet.window.Window(fullscreen=True)\n",
    "else:\n",
    "    window = pyglet.window.Window(\n",
    "        frame_width, frame_height, \n",
    "        resizable=False,\n",
    "        caption='vid-viz')\n",
    "    window.set_location(0, 0)\n",
    "\n",
    "image = pyglet.image.load('/media/data/Dropbox/Git/vid-viz/data/tree-00.jpg')\n",
    "frame = cv2.imread('/media/data/Dropbox/Git/vid-viz/data/tree-00.jpg')\n",
    "frame1 = frame[:600,:500,:]\n",
    "\n",
    "key_list = [False for i in range(256)]\n",
    "ni = NumpyImage(frame)\n",
    "\n",
    "@window.event\n",
    "def on_draw():\n",
    "    window.clear()\n",
    "    ni.texture.blit(0, 0)\n",
    "    \n",
    "@window.event\n",
    "def on_key_press(symbol, modifiers):\n",
    "    if symbol == key.A:\n",
    "        print('The \"A\" key was pressed.')\n",
    "    elif symbol == key.LEFT:\n",
    "        print('The left arrow key was pressed.')\n",
    "        ni.view_new_array(frame)\n",
    "    elif symbol == key.ENTER:\n",
    "        print('The enter key was pressed.')\n",
    "        # frame = cv2.imread('/media/data/Dropbox/Git/vid-viz/data/waves-04.jpg')\n",
    "        ni.view_new_array(np.zeros_like(frame))\n",
    "    elif symbol == key.ESCAPE:\n",
    "        key_list[0] = True\n",
    "\n",
    "while(True):\n",
    "    \n",
    "    pyglet.clock.tick()\n",
    "\n",
    "    for window in pyglet.app.windows:\n",
    "        window.switch_to()\n",
    "        window.dispatch_events()\n",
    "        window.dispatch_event('on_draw')\n",
    "        window.flip()\n",
    "    \n",
    "    if key_list[0]:\n",
    "        break\n",
    "        \n",
    "window.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"vid-viz main loop using pyglet to handle window creation\n",
    "\n",
    "KEYBOARD INPUTS:\n",
    "    number keys - choose effect (see viztools.py for detailed keyboard input for each effect)\n",
    "        0 - thresholding\n",
    "        1 - alien\n",
    "        2 - rgbwalk\n",
    "        3 - rgbburst\n",
    "        4 - huebloom\n",
    "        5 - hueswirl\n",
    "        6 - huecrusher\n",
    "    q - quit effect (then number keys are once again available for choosing a new effect)\n",
    "    ` - enable toggling of border effects ('t' to toggle, tab to switch processing/border order)\n",
    "    spacebar - cycle through sources\n",
    "    backspace - quit border effect editing\n",
    "    esc - exit loop\n",
    "\"\"\"\n",
    "\n",
    "# file_type options : 'cam' | 'video' | 'image' | 'auto'\n",
    "source_index = 0\n",
    "source_list = []\n",
    "source_list.append({\n",
    "    'file_loc': 'hueswirlchain',\n",
    "    'file_type': 'auto'})\n",
    "source_list.append({\n",
    "    'file_loc': None,\n",
    "    'file_type': 'cam'})\n",
    "source_list.append({\n",
    "    'file_loc': '/media/data/Dropbox/Git/vid-viz/data/snowflake-02.mp4',\n",
    "    'file_type': 'video'})\n",
    "source_list.append({\n",
    "    'file_loc': '/media/data/Dropbox/Git/vid-viz/data/tree-00.jpg',\n",
    "    'file_type': 'image'})\n",
    "source_list.append({\n",
    "    'file_loc': '/media/data/Dropbox/Git/vid-viz/data/honeycomb-00.jpg',\n",
    "    'file_type': 'image'})\n",
    "# source_list.append({\n",
    "#     'file_loc': '/media/data/Dropbox/Git/vid-viz/data/waves-00.jpg',\n",
    "#     'file_type': 'image'})\n",
    "# source_list.append({\n",
    "#     'file_loc': '/media/data/Dropbox/Git/vid-viz/data/waves-01.jpg',\n",
    "#     'file_type': 'image'})\n",
    "# source_list.append({\n",
    "#     'file_loc': '/media/data/Dropbox/Git/vid-viz/data/waves-02.jpg',\n",
    "#     'file_type': 'image'})\n",
    "# source_list.append({\n",
    "#     'file_loc': '/media/data/Dropbox/Git/vid-viz/data/waves-03.jpg',\n",
    "#     'file_type': 'image'})\n",
    "source_list.append({\n",
    "    'file_loc': '/media/data/Dropbox/Git/vid-viz/data/waves-04.jpg',\n",
    "    'file_type': 'image'})\n",
    "# source_list.append({\n",
    "#     'file_loc': '/media/data/Dropbox/Git/vid-viz/data/waves-05.jpg',\n",
    "#     'file_type': 'image'})\n",
    "\n",
    "source = None\n",
    "num_sources = len(source_list)\n",
    "\n",
    "# general user parameters\n",
    "disp_full_screen = False\n",
    "frame_width = int(1980/2)\n",
    "frame_height = int(1200/2)\n",
    "# frame_width = int(1024)\n",
    "# frame_height = int(768)\n",
    "target_fps = 20.0\n",
    "\n",
    "# initialize key handler\n",
    "effect_index = None\n",
    "key_list = [False for i in range(256)]\n",
    "\n",
    "# set pre/post-processing options\n",
    "post_process = False      # whether or not post-processing is active effect\n",
    "post_process_pre = False  # whether post-processing pre/proceeds other effects\n",
    "\n",
    "# initialize processing objects\n",
    "effects = [\n",
    "    vv.Threshold(),      # 0\n",
    "    vv.Alien(),          # 1\n",
    "    vv.RGBWalk(),        # 2\n",
    "    vv.RGBBurst(),       # 3\n",
    "    vv.HueBloom(),       # 4\n",
    "    vv.HueSwirl(),       # 5\n",
    "    vv.HueSwirlMover(),  # 6\n",
    "    vv.HueCrusher()]     # 7\n",
    "num_effects = len(effects)\n",
    "border = vv.Border()\n",
    "postproc = vv.PostProcess()\n",
    "    \n",
    "# create window with pyglet\n",
    "window = pyglet.window.Window()\n",
    "\n",
    "new_source = True\n",
    "while(True):\n",
    "\n",
    "    time_pre = time.time()\n",
    "    \n",
    "    # get keyboard input\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    key_list[key] = True\n",
    "    if key == 27:\n",
    "        # escape key; exit program\n",
    "        break\n",
    "    elif key == ord('q'):\n",
    "        # quit current effect\n",
    "        effect_index = None\n",
    "    elif key == ord('\\b'):\n",
    "        post_process = False\n",
    "    elif key == ord('`'):\n",
    "        post_process = True\n",
    "    elif key == ord(' '):\n",
    "        source_index = (source_index + 1) % num_sources\n",
    "        new_source = True\n",
    "    elif key == ord('\\t'):\n",
    "        # only change post-processing order if in post-process mode\n",
    "        if post_process:\n",
    "            post_process_pre = not post_process_pre\n",
    "            \n",
    "    if new_source:\n",
    "        \n",
    "        # reset necessary parameters\n",
    "        new_source = False\n",
    "        effect_index = None\n",
    "        fr_count = 0\n",
    "        for _, effect in enumerate(effects):\n",
    "            effect.reset()\n",
    "        border.reset()\n",
    "        postproc.reset()\n",
    "        \n",
    "        # free previous resources\n",
    "        if source is 'cam' or source is 'video':\n",
    "            cap.release()\n",
    "        \n",
    "        # load source\n",
    "        source = source_list[source_index]['file_type']\n",
    "        if source is 'cam':\n",
    "            cap = cv2.VideoCapture(0)\n",
    "            TOTAL_FRAME_COUNT = float('inf')\n",
    "            frame_mask = None\n",
    "        elif source is 'video':\n",
    "            cap = cv2.VideoCapture(source_list[source_index]['file_loc'])\n",
    "            # target_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "            TOTAL_FRAME_COUNT = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "            frame_mask = None\n",
    "        elif source is 'image':\n",
    "            frame_orig = cv2.imread(source_list[source_index]['file_loc'])\n",
    "            TOTAL_FRAME_COUNT = float('inf')\n",
    "            frame_mask = np.copy(frame_orig)   \n",
    "        elif source is 'auto':\n",
    "            if source_list[source_index]['file_loc'] is 'hueswirlchain':\n",
    "                auto_effect = auto.HueSwirlChain(frame_width, frame_height)\n",
    "            else:\n",
    "                print('Invalid auto effect')\n",
    "            TOTAL_FRAME_COUNT = float('inf')\n",
    "        else:\n",
    "            print('Invalid source type')          \n",
    "    \n",
    "    # get frame and relevant info\n",
    "    if source is 'cam' or source is 'video':\n",
    "        ret, frame = cap.read()\n",
    "    elif source is 'image':\n",
    "        frame = np.copy(frame_orig)\n",
    "    elif source is 'auto':\n",
    "        frame = auto_effect.process(key_list)\n",
    "    \n",
    "    if source is not 'auto':\n",
    "        # get uniform frame sizes \n",
    "        frame = util.resize(frame, frame_width, frame_height)\n",
    "    \n",
    "    # update current effect\n",
    "    if effect_index is None:\n",
    "        for num in range(10):\n",
    "            if key == ord(str(num)):\n",
    "                effect_index = num\n",
    "                key_list[key] = False\n",
    "    \n",
    "    # apply borders before effect\n",
    "    if post_process_pre:\n",
    "        if post_process:\n",
    "            frame = border.process(frame, key_list)\n",
    "        else:\n",
    "            frame = border.process(frame, key_list, key_lock=True)\n",
    "    \n",
    "    # process frame\n",
    "    if source is not 'auto' and effect_index is not None:\n",
    "        if post_process:\n",
    "            frame = effects[effect_index].process(frame, key_list, key_lock=True)            \n",
    "        else:\n",
    "            frame = effects[effect_index].process(frame, key_list)\n",
    "            \n",
    "    # apply borders after effect\n",
    "    if not post_process_pre:\n",
    "        if post_process:\n",
    "            frame = border.process(frame, key_list)\n",
    "#             frame = postproc.process(frame, key_list)\n",
    "        else:\n",
    "            frame = border.process(frame, key_list, key_lock=True)\n",
    "#             frame = postproc.process(frame, key_list, key_lock=True)\n",
    "    \n",
    "    # display frame\n",
    "\n",
    "    \n",
    "    # control animation\n",
    "    fr_count += 1\n",
    "    if fr_count == TOTAL_FRAME_COUNT:\n",
    "        # reset frame postion to 1 (not zero so window isn't moved)\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, 1)\n",
    "        fr_count = 1\n",
    "\n",
    "    # calculate, limit and output fps\n",
    "    time_tot = time.time() - time_pre\n",
    "    if time_tot < 1/target_fps:\n",
    "        time.sleep(1/target_fps - time_tot)\n",
    "    time_tot = time.time() - time_pre\n",
    "    print('\\r%03i fps' % (1.0 / time_tot), end='')\n",
    "#     print('\\r%02i' % effects[5].PROPS[4]['VAL'], end='')\n",
    "#     stdscr.addstr(0, 0, '%03i fps' % (1.0 / time_tot))\n",
    "#     stdscr.addstr(1, 0, '%05i frames' % fr_count)\n",
    "#     stdscr.refresh()\n",
    "    \n",
    "#     frame_final = np.copy(frame)\n",
    "    \n",
    "    # reset key list (for pressed keys that are not reset by effect object(s))\n",
    "    key_list[key] = False\n",
    "    \n",
    "if source is 'cam' or source is 'video':\n",
    "    cap.release()\n",
    "cv2.destroyWindow('frame')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"vid-viz main loop using OpenCV to handle window creation\n",
    "\n",
    "KEYBOARD INPUTS:\n",
    "    number keys - choose effect (see viztools.py for detailed keyboard input for each effect)\n",
    "        0 - thresholding\n",
    "        1 - alien\n",
    "        2 - rgbwalk\n",
    "        3 - rgbburst\n",
    "        4 - huebloom\n",
    "        5 - hueswirl\n",
    "        6 - huecrusher\n",
    "    q - quit effect (then number keys are once again available for choosing a new effect)\n",
    "    ` - enable toggling of border effects ('t' to toggle, tab to switch processing/border order)\n",
    "    spacebar - cycle through sources\n",
    "    backspace - quit border effect editing\n",
    "    esc - exit loop\n",
    "\"\"\"\n",
    "\n",
    "# file_type options : 'cam' | 'video' | 'image' | 'auto'\n",
    "source_index = 0\n",
    "source_list = []\n",
    "source_list.append({\n",
    "    'file_loc': 'hueswirlchain',\n",
    "    'file_type': 'auto'})\n",
    "source_list.append({\n",
    "    'file_loc': None,\n",
    "    'file_type': 'cam'})\n",
    "source_list.append({\n",
    "    'file_loc': '/media/data/Dropbox/Git/vid-viz/data/snowflake-02.mp4',\n",
    "    'file_type': 'video'})\n",
    "source_list.append({\n",
    "    'file_loc': '/media/data/Dropbox/Git/vid-viz/data/tree-00.jpg',\n",
    "    'file_type': 'image'})\n",
    "source_list.append({\n",
    "    'file_loc': '/media/data/Dropbox/Git/vid-viz/data/honeycomb-00.jpg',\n",
    "    'file_type': 'image'})\n",
    "# source_list.append({\n",
    "#     'file_loc': '/media/data/Dropbox/Git/vid-viz/data/waves-00.jpg',\n",
    "#     'file_type': 'image'})\n",
    "# source_list.append({\n",
    "#     'file_loc': '/media/data/Dropbox/Git/vid-viz/data/waves-01.jpg',\n",
    "#     'file_type': 'image'})\n",
    "# source_list.append({\n",
    "#     'file_loc': '/media/data/Dropbox/Git/vid-viz/data/waves-02.jpg',\n",
    "#     'file_type': 'image'})\n",
    "# source_list.append({\n",
    "#     'file_loc': '/media/data/Dropbox/Git/vid-viz/data/waves-03.jpg',\n",
    "#     'file_type': 'image'})\n",
    "source_list.append({\n",
    "    'file_loc': '/media/data/Dropbox/Git/vid-viz/data/waves-04.jpg',\n",
    "    'file_type': 'image'})\n",
    "# source_list.append({\n",
    "#     'file_loc': '/media/data/Dropbox/Git/vid-viz/data/waves-05.jpg',\n",
    "#     'file_type': 'image'})\n",
    "\n",
    "source = None\n",
    "num_sources = len(source_list)\n",
    "\n",
    "# general user parameters\n",
    "disp_full_screen = False\n",
    "frame_width = int(1980/2)\n",
    "frame_height = int(1200/2)\n",
    "# frame_width = int(1024)\n",
    "# frame_height = int(768)\n",
    "target_fps = 20.0\n",
    "\n",
    "# initialize key handler\n",
    "effect_index = None\n",
    "key_list = [False for i in range(256)]\n",
    "\n",
    "# set pre/post-processing options\n",
    "post_process = False      # whether or not post-processing is active effect\n",
    "post_process_pre = False  # whether post-processing pre/proceeds other effects\n",
    "\n",
    "# initialize processing objects\n",
    "effects = [\n",
    "    vv.Threshold(),      # 0\n",
    "    vv.Alien(),          # 1\n",
    "    vv.RGBWalk(),        # 2\n",
    "    vv.RGBBurst(),       # 3\n",
    "    vv.HueBloom(),       # 4\n",
    "    vv.HueSwirl(),       # 5\n",
    "    vv.HueSwirlMover(),  # 6\n",
    "    vv.HueCrusher()]     # 7\n",
    "num_effects = len(effects)\n",
    "border = vv.Border()\n",
    "postproc = vv.PostProcess()\n",
    "    \n",
    "new_source = True\n",
    "while(True):\n",
    "\n",
    "    time_pre = time.time()\n",
    "    \n",
    "    # get keyboard input\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    key_list[key] = True\n",
    "    if key == 27:\n",
    "        # escape key; exit program\n",
    "        break\n",
    "    elif key == ord('q'):\n",
    "        # quit current effect\n",
    "        effect_index = None\n",
    "    elif key == ord('\\b'):\n",
    "        post_process = False\n",
    "    elif key == ord('`'):\n",
    "        post_process = True\n",
    "    elif key == ord(' '):\n",
    "        source_index = (source_index + 1) % num_sources\n",
    "        new_source = True\n",
    "    elif key == ord('\\t'):\n",
    "        # only change post-processing order if in post-process mode\n",
    "        if post_process:\n",
    "            post_process_pre = not post_process_pre\n",
    "            \n",
    "    if new_source:\n",
    "        \n",
    "        # reset necessary parameters\n",
    "        new_source = False\n",
    "        effect_index = None\n",
    "        fr_count = 0\n",
    "        for _, effect in enumerate(effects):\n",
    "            effect.reset()\n",
    "        border.reset()\n",
    "        postproc.reset()\n",
    "        \n",
    "        # free previous resources\n",
    "        if source is 'cam' or source is 'video':\n",
    "            cap.release()\n",
    "        \n",
    "        # load source\n",
    "        source = source_list[source_index]['file_type']\n",
    "        if source is 'cam':\n",
    "            cap = cv2.VideoCapture(0)\n",
    "            TOTAL_FRAME_COUNT = float('inf')\n",
    "            frame_mask = None\n",
    "        elif source is 'video':\n",
    "            cap = cv2.VideoCapture(source_list[source_index]['file_loc'])\n",
    "            # target_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "            TOTAL_FRAME_COUNT = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "            frame_mask = None\n",
    "        elif source is 'image':\n",
    "            frame_orig = cv2.imread(source_list[source_index]['file_loc'])\n",
    "            TOTAL_FRAME_COUNT = float('inf')\n",
    "            frame_mask = np.copy(frame_orig)   \n",
    "        elif source is 'auto':\n",
    "            if source_list[source_index]['file_loc'] is 'hueswirlchain':\n",
    "                auto_effect = auto.HueSwirlChain(frame_width, frame_height)\n",
    "            else:\n",
    "                print('Invalid auto effect')\n",
    "            TOTAL_FRAME_COUNT = float('inf')\n",
    "        else:\n",
    "            print('Invalid source type')          \n",
    "    \n",
    "    # get frame and relevant info\n",
    "    if source is 'cam' or source is 'video':\n",
    "        ret, frame = cap.read()\n",
    "    elif source is 'image':\n",
    "        frame = np.copy(frame_orig)\n",
    "    elif source is 'auto':\n",
    "        frame = auto_effect.process(key_list)\n",
    "    \n",
    "    if source is not 'auto':\n",
    "        # get uniform frame sizes \n",
    "        frame = util.resize(frame, frame_width, frame_height)\n",
    "    \n",
    "    # update current effect\n",
    "    if effect_index is None:\n",
    "        for num in range(10):\n",
    "            if key == ord(str(num)):\n",
    "                effect_index = num\n",
    "                key_list[key] = False\n",
    "    \n",
    "    # apply borders before effect\n",
    "    if post_process_pre:\n",
    "        if post_process:\n",
    "            frame = border.process(frame, key_list)\n",
    "        else:\n",
    "            frame = border.process(frame, key_list, key_lock=True)\n",
    "    \n",
    "    # process frame\n",
    "    if source is not 'auto' and effect_index is not None:\n",
    "        if post_process:\n",
    "            frame = effects[effect_index].process(frame, key_list, key_lock=True)            \n",
    "        else:\n",
    "            frame = effects[effect_index].process(frame, key_list)\n",
    "            \n",
    "    # apply borders after effect\n",
    "    if not post_process_pre:\n",
    "        if post_process:\n",
    "            frame = border.process(frame, key_list)\n",
    "#             frame = postproc.process(frame, key_list)\n",
    "        else:\n",
    "            frame = border.process(frame, key_list, key_lock=True)\n",
    "#             frame = postproc.process(frame, key_list, key_lock=True)\n",
    "    \n",
    "    # display frame\n",
    "    if disp_full_screen:\n",
    "        cv2.namedWindow('frame', cv2.WND_PROP_FULLSCREEN)\n",
    "        cv2.setWindowProperty('frame', cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "        cv2.imshow('frame', frame)\n",
    "    else:\n",
    "        cv2.imshow('frame', frame)\n",
    "        if fr_count == 0:\n",
    "            cv2.moveWindow('frame', 0, 0)\n",
    "    \n",
    "    # control animation\n",
    "    fr_count += 1\n",
    "    if fr_count == TOTAL_FRAME_COUNT:\n",
    "        # reset frame postion to 1 (not zero so window isn't moved)\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, 1)\n",
    "        fr_count = 1\n",
    "\n",
    "    # calculate, limit and output fps\n",
    "    time_tot = time.time() - time_pre\n",
    "    if time_tot < 1/target_fps:\n",
    "        time.sleep(1/target_fps - time_tot)\n",
    "    time_tot = time.time() - time_pre\n",
    "    print('\\r%03i fps' % (1.0 / time_tot), end='')\n",
    "#     print('\\r%02i' % effects[5].PROPS[4]['VAL'], end='')\n",
    "#     stdscr.addstr(0, 0, '%03i fps' % (1.0 / time_tot))\n",
    "#     stdscr.addstr(1, 0, '%05i frames' % fr_count)\n",
    "#     stdscr.refresh()\n",
    "    \n",
    "#     frame_final = np.copy(frame)\n",
    "    \n",
    "    # reset key list (for pressed keys that are not reset by effect object(s))\n",
    "    key_list[key] = False\n",
    "    \n",
    "if source is 'cam' or source is 'video':\n",
    "    cap.release()\n",
    "cv2.destroyWindow('frame')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(vv)\n",
    "reload(auto)\n",
    "reload(util)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "string = source_list[source_index]['file_loc']\n",
    "type(string)\n",
    "type('hueswirl-chain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import PIL.Image\n",
    "PIL.Image.fromarray(frame_final).save('/media/data/Dropbox/image_play/hue-bloom/final/tree-00.jpg', 'jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img1 = cv2.imread('/media/data/Dropbox/Git/vid-viz/data/test_img.png')\n",
    "img1 = util.resize(img1, 1920, 1200)\n",
    "\n",
    "# img0 = 0\n",
    "# img2 = cv2.addWeighted(img0, 0.1, img1, 0.9, 0)\n",
    "# %timeit cv2.addWeighted(img0, 0.1, img1, 0.9, 0)\n",
    "\n",
    "# im_width, im_height, _ = img1.shape\n",
    "# %timeit cv2.warpAffine(img1, \\\n",
    "#             np.float32([[1, 0, 100], \\\n",
    "#                         [0, 1, 200]]), \\\n",
    "#             (im_width, im_height))\n",
    "\n",
    "%timeit cv2.threshold(img1, 128, 255, cv2.THRESH_TOZERO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "frame_back_0 = np.random.rand(2,2,3)\n",
    "frame_back_1 = np.random.rand(4,4,3)\n",
    "frame_back0 = cv2.resize(\n",
    "    frame_back_0,\n",
    "    (512, 512),\n",
    "    interpolation=cv2.INTER_LINEAR)\n",
    "frame_back1 = cv2.resize(\n",
    "    frame_back_1,\n",
    "    (512, 512),\n",
    "    interpolation=cv2.INTER_LINEAR)\n",
    "frame_back = 255.0 * (frame_back0 / 2 + frame_back1 / 2)\n",
    "frame_back = frame_back.astype('uint8')\n",
    "\n",
    "\n",
    "img_noise = np.random.uniform(size=(1024,1024,3))\n",
    "\n",
    "hw = img_noise.shape[:2]\n",
    "for i in range(8):\n",
    "    tmp = np.random.uniform(size=(hw[0]//(2**(i+1)), hw[1]//(2**(i+1)), 3))\n",
    "#     tmp = np.random.rand(2**(i+1), 2**(i+1), 3)\n",
    "    img_noise = img_noise + cv2.resize(tmp, hw, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    \n",
    "img_noise = 255.0 * (img_noise - np.min(img_noise)) / (np.max(img_noise) - np.min(img_noise))\n",
    "img_noise = img_noise.astype('uint8')\n",
    "\n",
    "while True:\n",
    "\n",
    "    # get keyboard input\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    \n",
    "    if key == 27:\n",
    "        # escape key\n",
    "        break\n",
    "        \n",
    "    cv2.imshow('frame', img_noise)\n",
    "        \n",
    "cv2.destroyWindow('frame')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "frame = cv2.imread('/media/data/Dropbox/Git/vid-viz/data/test_img.png')\n",
    "frame = util.resize(frame, int(1920/2), int(1200/2))\n",
    "\n",
    "# extract hue values\n",
    "frame = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "[im_height, im_width, _] = frame.shape\n",
    "hue_final = np.zeros((im_height, im_width), dtype='uint8')\n",
    "\n",
    "chunk_center = 128\n",
    "chunk_widths_og = 128\n",
    "chunk_width = 8\n",
    "center_offset = 0\n",
    "\n",
    "# human-readable names\n",
    "num_chunks = 3\n",
    "center_offset = 0\n",
    "chunk_width = 8\n",
    "\n",
    "chunk_widths_og = int(256 / num_chunks)\n",
    "chunk_range_mins = np.zeros((num_chunks, 1), 'uint8')\n",
    "chunk_range_maxs = np.zeros((num_chunks, 1), 'uint8')\n",
    "chunk_centers = np.zeros((num_chunks, 1), 'uint8')\n",
    "for chunk in range(num_chunks):\n",
    "    chunk_range_mins[chunk] = chunk * chunk_widths_og\n",
    "    chunk_range_maxs[chunk] = (chunk + 1) * chunk_widths_og - 1\n",
    "    chunk_centers[chunk] = chunk_range_mins[chunk] + int(chunk_widths_og / 2)\n",
    "chunk_range_maxs[-1] = 255\n",
    "    \n",
    "# process image\n",
    "if len(frame.shape) == 3:\n",
    "    [im_height, im_width, _] = frame.shape\n",
    "elif len(frame.shape) == 2:\n",
    "    [im_height, im_width] = frame.shape\n",
    "\n",
    "# extract hue values\n",
    "frame = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "hue_final = np.zeros((im_height, im_width), dtype='uint8')\n",
    "\n",
    "# scale whole image\n",
    "scale = chunk_width / chunk_widths_og\n",
    "frame_scaled = cv2.addWeighted(0, 1 - scale, frame, scale, 0)\n",
    "\n",
    "for chunk in range(num_chunks):\n",
    "\n",
    "    chunk_center = chunk_centers[chunk]\n",
    "\n",
    "    # get rid of values outside bounds of chunk\n",
    "    hue_mask = cv2.inRange(frame[:, :, 0],\n",
    "                           chunk_range_mins[chunk],\n",
    "                           chunk_range_maxs[chunk])\n",
    "    # hue_mask is now a mask for the location of values in a specific\n",
    "    # hue band;\n",
    "    hue = frame_scaled[:, :, 0] + chunk_center - int(chunk_width / 2) + \\\n",
    "        center_offset\n",
    "    hue = cv2.bitwise_and(hue, hue_mask)\n",
    "\n",
    "    # put into final hue array (bitwise or takes all nonzero vals)\n",
    "    hue_final = cv2.bitwise_or(hue_final, hue)\n",
    "\n",
    "# return to bgr format\n",
    "frame[:, :, 0] = hue_final\n",
    "frame = cv2.cvtColor(frame, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "while(True):\n",
    "    \n",
    "    # get keyboard input\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    \n",
    "    print('\\r%g' % key, end='')\n",
    "    \n",
    "    if key == 27:\n",
    "        # escape key\n",
    "        break\n",
    "        \n",
    "    cv2.imshow('frame', frame)\n",
    "        \n",
    "cv2.destroyWindow('frame')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_orig = cv2.imread('/media/data/Dropbox/Git/vid-viz/data/honeycomb_01.jpg')\n",
    "img_orig = cv2.resize(\n",
    "    img_orig,\n",
    "    None,\n",
    "    fx=0.5,\n",
    "    fy=0.5,\n",
    "    interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "# get mask\n",
    "img_gray = cv2.cvtColor(img_orig, cv2.COLOR_BGR2GRAY)\n",
    "img_gray = cv2.medianBlur(img_gray, 11)\n",
    "img_mask = cv2.adaptiveThreshold(\n",
    "    img_gray,\n",
    "    255, # thresh ceil\n",
    "    cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "    cv2.THRESH_BINARY_INV,\n",
    "    21, # thresh block\n",
    "    4 # thresh bias\n",
    ")\n",
    "img_mask2 = cv2.adaptiveThreshold(\n",
    "    img_gray,\n",
    "    255, # thresh ceil\n",
    "    cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "    cv2.THRESH_BINARY,\n",
    "    21, # thresh block\n",
    "    4 # thresh bias\n",
    ")\n",
    "[mask_height, mask_width] = img_mask.shape\n",
    "\n",
    "# get hue background\n",
    "back_height = 10 #int(mask_height/60.0)\n",
    "back_width = 10 #int(mask_width/60.0)\n",
    "img_back = np.ones((back_height, back_width, 3))\n",
    "img_back[:, :, 0] = np.random.rand(back_height, back_width)\n",
    "img_back = cv2.resize(img_back,\n",
    "    (mask_width, mask_height),\n",
    "    interpolation=cv2.INTER_CUBIC)\n",
    "img_back = 255.0 * img_back\n",
    "img_back = img_back.astype('uint8')\n",
    "img_back = cv2.cvtColor(img_back, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "# get blurred background\n",
    "img_back2 = img_back\n",
    "for chan in range(3):\n",
    "    img_back2[:, :, chan] = cv2.bitwise_and(img_back[:, :, chan], img_mask)\n",
    "REDUCE_SIZE = False\n",
    "if REDUCE_SIZE:\n",
    "    img_back2 = cv2.resize(\n",
    "        img_back2,\n",
    "        None,\n",
    "        fx=0.10,\n",
    "        fy=0.10,\n",
    "        interpolation=cv2.INTER_LINEAR)\n",
    "    img_back2 = cv2.GaussianBlur(img_back2, (5,5), 0)\n",
    "    img_back2 = cv2.resize(\n",
    "        img_back2,\n",
    "        (mask_width, mask_height),\n",
    "        interpolation=cv2.INTER_LINEAR)\n",
    "else:\n",
    "    img_back2 = cv2.GaussianBlur(img_back2, (71, 71), 0)\n",
    "\n",
    "# remask blurred background\n",
    "img = img_back2\n",
    "for chan in range(3):\n",
    "    img[:, :, chan] = cv2.bitwise_and(img_back2[:, :, chan], img_mask2)\n",
    "    \n",
    "while(True):\n",
    "    \n",
    "    # get keyboard input\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    \n",
    "    if key == 27:\n",
    "        # escape key\n",
    "        break\n",
    "        \n",
    "    cv2.imshow('frame', img_back2)\n",
    "    cv2.moveWindow('frame', 0, 0)\n",
    "\n",
    "cv2.destroyWindow('frame')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To patrol-cycle an mp4 with ffmpeg\n",
    "* ffmpeg -i source.mp4 -vf reverse source_rev.mp4\n",
    "* ffmpeg -f concat -i concat_list.txt -c copy concated.mp4\n",
    "\n",
    "##### concat_list.txt\n",
    "file '/path/to/vid0.mp4'\n",
    "\n",
    "file '/path/to/vid1.mp4'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
